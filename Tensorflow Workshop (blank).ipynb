{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition with Convolutional Neural Nets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def show_images(images, min_width = 0):\n",
    "    images = np.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "    \n",
    "    sqrtn = max(min_width, sqrtn)\n",
    "        \n",
    "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
    "    return\n",
    "\n",
    "def visualise_errors(incorrect_classifications):\n",
    "    for digit_class in range(10):        \n",
    "        sample = [class_prototype[digit_class]] + incorrect_classifications[digit_class][:15]            \n",
    "        show_images(X_test[sample,:], 16)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will be working on the MNIST dataset, which is 60,000 training and 10,000 test images. Each picture contains a centered image of white digit on black background (0 through 9). This was one of the first datasets used to train convolutional neural networks and it is fairly easy -- a standard CNN model can easily exceed 99% accuracy. \n",
    "\n",
    "To simplify our code here, we will use the TensorFlow MNIST wrapper, which downloads and loads the MNIST dataset. See the [documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/datasets/mnist.py) for more information about the interface. The default parameters will take 5,000 of the training examples and place them into a validation dataset. The data will be saved into a folder called `MNIST_data`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neigbours (kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind kNN is to classify a digit by looking at its 'closest' analogy.  That is, to compare an unknown digit to a set of known digits.  \n",
    "\n",
    "Some problems can be solved quite well by this deceptively simple algorithm, especially if a good distance metric is used.  \n",
    "\n",
    "The 'k' in kNN refers the number of closest examples to consider.  For example, k=5 would mean to take the 5 most similar digits and pick the most common one.\n",
    "\n",
    "Each problem will have a different best k value.  But 3 or 5 usually works quite well.\n",
    "\n",
    "kNN is also great at providing a **baseline**.  A more advanced model performing worse than kNN is a strong indicator of a bug in your algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the test and training data\n",
    "\n",
    "The goal is to learn how to predict **y** from **X**.  Where **X** is is the image, and **y** is the label (i.e. 0,1,2...)\n",
    "\n",
    "We will use the training data to learn how to predict digits, and the test data to check how well the model is working.  It is important that the model never sees the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a (n=5000) training sample, and a (n=500) test sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Model\n",
    "\n",
    "Now we setup our model in TensorFlow.  At this point, *we are not doing any of the calculations*.  We are simply creating a graph that will be used during training.  You can think of this as creating a 'blueprint' describing what calculations to perform during training.\n",
    "\n",
    "TensorFlow operations can be performed using method calls, e.g. c = tf.add(a,b), or by using operators, e.g. c = a + b\n",
    "\n",
    "We will also make use of the tf.nn module which contains some very useful support functions for neural nets.\n",
    "\n",
    "The following code was modified from the [tensorflow examples](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/2_BasicModels/nearest_neighbor.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "The kNN algorithm doesn't really need to train, as it simply memorises the training data.  So at this point we are simply going to evaluate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the miss clasified examples\n",
    "\n",
    "It's always a good idea to take a look at what kinds of errors the algorithm is making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some missclassifed examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Convolutional Neural Net\n",
    "\n",
    "### What is a Convolutional Neural Net?\n",
    "\n",
    "\n",
    "In a standard neural net, each neuron responds based on a linear combination of inputs from the previous layer.\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" width = 40%>\n",
    "\n",
    "In a convolutional neural net, each neuron is a 'filter' which responds to different kinds of 2d patterns.  At the base layers, these will simply be edge detectors, but higher layers neurons will trigger on more abstract concepts.  Each filter is run over the entire image and outputs a new image with the applied filter.  These filtered images are then 'stacked' on top of each other to create a 3D volume used as the input to the next layer.\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/cnn/cnn.jpeg\", width = 40%>\n",
    "\n",
    "We add pooling layers that reduce the size of the image.  The idea being that at deeper layers the exact details are not needed, just the general ideas.  Typically these pooling layers reduce the size of the image by 2 in each direction.\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/cnn/convnet.jpeg\">\n",
    "\n",
    "\n",
    "See the [CS231n](http://cs231n.github.io/convolutional-networks/) site for more information.\n",
    "\n",
    "Note: The following code was modified from [this](https://www.tensorflow.org/tutorials/layers) TensorFlow example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single layer CCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This time we will use the entire dataset.\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "class_prototype = [np.argmax(y_test, axis = 1).tolist().index(digit_class) for digit_class in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions for training / evaluation.\n",
    "def eval_model():\n",
    "    print(\"-\"*60)\n",
    "    test_accuracy = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0})\n",
    "    print(\"Test Error Rate {0:.2f}%\".format((1-test_accuracy)*100))\n",
    "    \n",
    "    predictions = pred.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0})\n",
    "    pred_class = np.argmax(predictions, axis = 1)\n",
    "    true_class = np.argmax(mnist.test.labels, axis = 1)\n",
    "    \n",
    "    incorrect_classifications = [[] for _ in range(10)]\n",
    "        \n",
    "    for i in range(true_class.shape[0]):\n",
    "        if pred_class[i] != true_class[i]:\n",
    "            incorrect_classifications[pred_class[i]].append(i)\n",
    "            \n",
    "    visualise_errors(incorrect_classifications)    \n",
    "    \n",
    "\n",
    "# train the model...\n",
    "def train_model(epocs = 10, batch_size = 64):\n",
    "\n",
    "    print(\"Training...\")\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    iterations = int(epocs * len(mnist.train.labels) / batch_size)\n",
    "\n",
    "    # Start training\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "\n",
    "        for i in range(iterations):\n",
    "\n",
    "            # get a new batch\n",
    "            batch = mnist.train.next_batch(batch_size)            \n",
    "\n",
    "            # evaluate every 100 steps\n",
    "            if i % 1000 == 0:\n",
    "                val_batch = mnist.validation.next_batch(1000)\n",
    "                train_batch = mnist.validation.next_batch(1000)\n",
    "\n",
    "                train_accuracy = accuracy.eval(feed_dict={X: train_batch[0], y: train_batch[1], keep_prob: 1.0})\n",
    "                val_accuracy = accuracy.eval(feed_dict={X: val_batch[0], y: val_batch[1], keep_prob: 1.0}) \n",
    "\n",
    "                loss_eval = loss.eval(feed_dict={X: batch[0], y: batch[1], keep_prob: 0.5})            \n",
    "                \n",
    "                epoc = (batch_size * i) / len(mnist.train.labels)\n",
    "\n",
    "                print('[epoc=%g] step %d, training accuracy %g validation accuracy %g loss %g' % (epoc, i, train_accuracy, val_accuracy, loss_eval))        \n",
    "\n",
    "            # train on this batch\n",
    "            train_op.run(feed_dict={X: batch[0], y: batch[1], keep_prob: 0.5})\n",
    "\n",
    "        eval_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two layer CCN\n",
    "\n",
    "Two layer model based on [LeNet-5](http://yann.lecun.com/exdb/lenet/ )\n",
    "\n",
    "See (http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
